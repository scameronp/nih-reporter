{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NIH-RePORTER-project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOxs3I8t3k+n+oXq7pJ2HRW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/scameronp/nih-reporter/blob/main/NIH_RePORTER_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Context\n",
        "\n",
        "This project aims at exploring gender disparities in science based on [NIH RePORTER](https://exporter.nih.gov/ExPORTER_Catalog.aspx?sid=1&index=0) project data from 1985 to 2020.\n",
        "\n",
        "It is supported by the [Canada Research Chair on the Transformations of Scholarly Communication](https://crctcs.openum.ca/en) (Prof. Vincent Larivi√®re)."
      ],
      "metadata": {
        "id": "8NmC-T7rEpEG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preprocessing"
      ],
      "metadata": {
        "id": "wwMeFO8IA9EC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: download CSV project files"
      ],
      "metadata": {
        "id": "dkRq4gKiWxtx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from urllib.request import urlretrieve\n",
        "import zipfile\n",
        "import tempfile\n",
        "\n",
        "\n",
        "LOCAL_SOURCE_DIR = '/content/downloads'\n",
        "# used to download zip files\n",
        "TMP_DIR = tempfile.gettempdir()\n",
        "BASE_URL = 'https://exporter.nih.gov/CSVs/final'\n",
        "\n",
        "\n",
        "for file_name in [f'RePORTER_PRJ_C_FY{year}.zip' for year in range(1985, 2021)]:\n",
        "    url = f'{BASE_URL}/{file_name}'\n",
        "\n",
        "    # download file in local\n",
        "    zip_path = f'{TMP_DIR}/{file_name}'\n",
        "    urlretrieve(url, zip_path)\n",
        "\n",
        "    # unzip\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(LOCAL_SOURCE_DIR)"
      ],
      "metadata": {
        "id": "fqDdxJHNW4Fl"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: headers uniformization and reordering"
      ],
      "metadata": {
        "id": "ImP_SQ08F3GC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ACTIVITY = 'ACTIVITY'\n",
        "ADMINISTERING_IC = 'ADMINISTERING_IC'\n",
        "APPLICATION_ID = 'APPLICATION_ID'\n",
        "APPLICATION_TYPE = 'APPLICATION_TYPE'\n",
        "ARRA_FUNDED = 'ARRA_FUNDED'\n",
        "AWARD_NOTICE_DATE = 'AWARD_NOTICE_DATE'\n",
        "BUDGET_END = 'BUDGET_END'\n",
        "BUDGET_START = 'BUDGET_START'\n",
        "CFDA_CODE = 'CFDA_CODE'\n",
        "CORE_PROJECT_NUM = 'CORE_PROJECT_NUM'\n",
        "DIRECT_COST_AMT = 'DIRECT_COST_AMT'\n",
        "ED_INST_TYPE = 'ED_INST_TYPE'\n",
        "FOA_NUMBER = 'FOA_NUMBER'\n",
        "FULL_PROJECT_NUM = 'FULL_PROJECT_NUM'\n",
        "FUNDING_ICS = 'FUNDING_ICS'\n",
        "FUNDING_MECHANISM = 'FUNDING_MECHANISM'\n",
        "FY = 'FY'\n",
        "IC_NAME = 'IC_NAME'\n",
        "INDIRECT_COST_AMT = 'INDIRECT_COST_AMT'\n",
        "NIH_SPENDING_CATS = 'NIH_SPENDING_CATS'\n",
        "ORG_CITY = 'ORG_CITY'\n",
        "ORG_COUNTRY = 'ORG_COUNTRY'\n",
        "ORG_DEPT = 'ORG_DEPT'\n",
        "ORG_DISTRICT = 'ORG_DISTRICT'\n",
        "ORG_DUNS = 'ORG_DUNS'\n",
        "ORG_FIPS = 'ORG_FIPS'\n",
        "ORG_IPF_CODE = 'ORG_IPF_CODE'\n",
        "ORG_NAME = 'ORG_NAME'\n",
        "ORG_STATE = 'ORG_STATE'\n",
        "ORG_ZIPCODE = 'ORG_ZIPCODE'\n",
        "PHR ='PHR'\n",
        "PI_IDS = 'PI_IDS'\n",
        "PI_NAMES = 'PI_NAMES'\n",
        "PROGRAM_OFFICER_NAME = 'PROGRAM_OFFICER_NAME'\n",
        "PROJECT_END = 'PROJECT_END'\n",
        "PROJECT_START = 'PROJECT_START'\n",
        "PROJECT_TERMS = 'PROJECT_TERMS'\n",
        "PROJECT_TITLE = 'PROJECT_TITLE'\n",
        "SERIAL_NUMBER = 'SERIAL_NUMBER'\n",
        "STUDY_SECTION = 'STUDY_SECTION'\n",
        "STUDY_SECTION_NAME = 'STUDY_SECTION_NAME'\n",
        "SUBPROJECT_ID = 'SUBPROJECT_ID'\n",
        "SUFFIX = 'SUFFIX'\n",
        "SUPPORT_YEAR = 'SUPPORT_YEAR'\n",
        "TOTAL_COST = 'TOTAL_COST'\n",
        "TOTAL_COST_SUB_PROJECT = 'TOTAL_COST_SUB_PROJECT'\n",
        "\n",
        "headers = [\n",
        "    APPLICATION_ID,\n",
        "    ACTIVITY,\n",
        "    ADMINISTERING_IC,\n",
        "    APPLICATION_TYPE,\n",
        "    ARRA_FUNDED,\n",
        "    AWARD_NOTICE_DATE,\n",
        "    BUDGET_START,\n",
        "    BUDGET_END,\n",
        "    CFDA_CODE,\n",
        "    CORE_PROJECT_NUM,\n",
        "    ED_INST_TYPE,\n",
        "    FOA_NUMBER,\n",
        "    FULL_PROJECT_NUM,\n",
        "    FUNDING_ICS,\n",
        "    FUNDING_MECHANISM,\n",
        "    FY,\n",
        "    IC_NAME,\n",
        "    NIH_SPENDING_CATS,\n",
        "    ORG_CITY,\n",
        "    ORG_COUNTRY,\n",
        "    ORG_DEPT,\n",
        "    ORG_DISTRICT,\n",
        "    ORG_DUNS,\n",
        "    ORG_FIPS,\n",
        "    ORG_IPF_CODE,\n",
        "    ORG_NAME,\n",
        "    ORG_STATE,\n",
        "    ORG_ZIPCODE,\n",
        "    PHR,\n",
        "    PI_IDS,\n",
        "    PI_NAMES,\n",
        "    PROGRAM_OFFICER_NAME,\n",
        "    PROJECT_START,\n",
        "    PROJECT_END,\n",
        "    PROJECT_TERMS,\n",
        "    PROJECT_TITLE,\n",
        "    SERIAL_NUMBER,\n",
        "    STUDY_SECTION,\n",
        "    STUDY_SECTION_NAME,\n",
        "    SUBPROJECT_ID,\n",
        "    SUFFIX,\n",
        "    SUPPORT_YEAR,\n",
        "    DIRECT_COST_AMT,\n",
        "    INDIRECT_COST_AMT,\n",
        "    TOTAL_COST,\n",
        "    TOTAL_COST_SUB_PROJECT\n",
        "                 ]"
      ],
      "metadata": {
        "id": "qeiB-LSZCyEs"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: CSV files merge"
      ],
      "metadata": {
        "id": "6XFGnghtDLM4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import os\n",
        "import codecs\n",
        "\n",
        "\n",
        "SOURCE_DIR = '/content/downloads'\n",
        "TARGET_FILE = '/content/output.tsv'\n",
        "\n",
        "\n",
        "def is_integer(string):\n",
        "    try:\n",
        "        int(string)\n",
        "        return True\n",
        "    except ValueError as a:\n",
        "        return False\n",
        "\n",
        "\n",
        "def is_corrupted(dict_row):\n",
        "    empty_column = None in dict_row\n",
        "    is_application_id_not_integer = not is_integer(dict_row[APPLICATION_ID])   \n",
        "    return empty_column or is_application_id_not_integer\n",
        "\n",
        "\n",
        "with codecs.open(TARGET_FILE, 'w', encoding='utf-8') as output_file:\n",
        "    writer = csv.DictWriter(output_file, fieldnames=headers, dialect=csv.excel_tab)\n",
        "    writer.writeheader()\n",
        "\n",
        "    csv_files = sorted(os.listdir(SOURCE_DIR))\n",
        "\n",
        "    for csv_file_name in csv_files:\n",
        "        print(csv_file_name)\n",
        "\n",
        "        with codecs.open(SOURCE_DIR + '/' + csv_file_name, 'r', encoding='ISO-8859-1') as csv_file_descriptor:\n",
        "            reader = csv.DictReader(csv_file_descriptor, delimiter=',', quotechar='\"')\n",
        "            for index, dict_row in enumerate(reader):\n",
        "                if is_corrupted(dict_row):\n",
        "                    print(csv_file_name, index, dict_row[APPLICATION_ID])\n",
        "                else:\n",
        "                    upper_dict = dict()\n",
        "                    for key, value in dict_row.items():\n",
        "                        try:\n",
        "                            upper_dict[key.upper()] = value.replace(\"\\n\", \"\")\n",
        "                        except Exception as e:\n",
        "                            print(e)\n",
        "                            print(dict_row)\n",
        "                            print(csv_file_name)\n",
        "                            #raise e\n",
        "                    writer.writerow(upper_dict)"
      ],
      "metadata": {
        "id": "7aPtvpzIC0oh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9497f5ee-6625-4d4e-9687-f9bac2ab6b86"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RePORTER_PRJ_C_FY1985.csv\n",
            "RePORTER_PRJ_C_FY1986.csv\n",
            "RePORTER_PRJ_C_FY1987.csv\n",
            "RePORTER_PRJ_C_FY1988.csv\n",
            "RePORTER_PRJ_C_FY1989.csv\n",
            "RePORTER_PRJ_C_FY1990.csv\n",
            "RePORTER_PRJ_C_FY1991.csv\n",
            "RePORTER_PRJ_C_FY1992.csv\n",
            "RePORTER_PRJ_C_FY1993.csv\n",
            "RePORTER_PRJ_C_FY1994.csv\n",
            "RePORTER_PRJ_C_FY1995.csv\n",
            "RePORTER_PRJ_C_FY1996.csv\n",
            "RePORTER_PRJ_C_FY1997.csv\n",
            "RePORTER_PRJ_C_FY1998.csv\n",
            "RePORTER_PRJ_C_FY1999.csv\n",
            "RePORTER_PRJ_C_FY2000.csv\n",
            "RePORTER_PRJ_C_FY2001.csv\n",
            "RePORTER_PRJ_C_FY2002.csv\n",
            "RePORTER_PRJ_C_FY2003.csv\n",
            "RePORTER_PRJ_C_FY2004.csv\n",
            "RePORTER_PRJ_C_FY2005.csv\n",
            "RePORTER_PRJ_C_FY2006.csv\n",
            "RePORTER_PRJ_C_FY2007.csv\n",
            "RePORTER_PRJ_C_FY2008.csv\n",
            "RePORTER_PRJ_C_FY2009.csv\n",
            "RePORTER_PRJ_C_FY2010.csv\n",
            "RePORTER_PRJ_C_FY2011.csv\n",
            "RePORTER_PRJ_C_FY2012.csv\n",
            "RePORTER_PRJ_C_FY2013.csv\n",
            "RePORTER_PRJ_C_FY2014.csv\n",
            "RePORTER_PRJ_C_FY2015.csv\n",
            "RePORTER_PRJ_C_FY2016_new.csv\n",
            "RePORTER_PRJ_C_FY2017_new.csv\n",
            "RePORTER_PRJ_C_FY2017_new.csv 46320 9350897\n",
            "RePORTER_PRJ_C_FY2018_new.csv\n",
            "RePORTER_PRJ_C_FY2018_new.csv 55939 9473820\n",
            "RePORTER_PRJ_C_FY2019_new.csv\n",
            "RePORTER_PRJ_C_FY2019_new.csv 3704 9629755\n",
            "RePORTER_PRJ_C_FY2020.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: contact PIs first name extraction"
      ],
      "metadata": {
        "id": "-SeT387SDQ9L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import codecs\n",
        "import itertools\n",
        "import re\n",
        "\n",
        "\n",
        "SOURCE_FILE = '/content/output.tsv'\n",
        "TARGET_FILE = '/content/pis.tsv'\n",
        "ENCODING = 'utf-8'\n",
        "\n",
        "\n",
        "def string_to_list(string):\n",
        "    pi_list = []\n",
        "    for string_part in string.rstrip('; ').split(';'):\n",
        "        string_part = string_part.strip(', ').replace('\"', '')\n",
        "        if string_part != '':\n",
        "            pi_list.append(string_part)\n",
        "    return pi_list\n",
        "\n",
        "def filter_contact_pi(pi_ids_or_names_list):\n",
        "    filtered_list = []\n",
        "    for item in pi_ids_or_names_list: \n",
        "         if '(contact)' in item:\n",
        "            filtered_list.append(item)\n",
        "    return filtered_list\n",
        "\n",
        "def extract_contact_pi(pi_ids_or_names_list):\n",
        "    if len(pi_ids_or_names_list) == 0:\n",
        "        return None, \"no_value\"\n",
        "    elif len(pi_ids_or_names_list) == 1:\n",
        "        return pi_ids_or_names_list[0], \"single_value\"\n",
        "    else:              \n",
        "        filtered_pi_ids_or_names = filter_contact_pi(pi_ids_or_names_list)\n",
        "        if len(filtered_pi_ids_or_names) == 0:\n",
        "            return pi_ids_or_names_list[0], \"multiple_values_but_no_explicit_contact_first_chosen\"\n",
        "        elif len(filtered_pi_ids_or_names) == 1:\n",
        "            return filtered_pi_ids_or_names[0], \"multiple_values_and_single_explicit_contact\"\n",
        "        else:\n",
        "            return filtered_pi_ids_or_names[0], \"multiple_values_and_multiple_explicit_contacts_first_chosen\"\n",
        "\n",
        "def extract_pi_first_name(full_name):\n",
        "    if full_name is None:\n",
        "        return None\n",
        "    else:\n",
        "        full_name_list = full_name.split(',')\n",
        "        if len(full_name_list) <= 1:\n",
        "            return None\n",
        "        else:\n",
        "            raw_first_name = full_name_list[1].replace('.', ' ').replace('(contact)', '')\n",
        "            final_first_name = re.sub(' +', ' ', raw_first_name)\n",
        "            first_name_parts = final_first_name.strip(' ').split(' ')\n",
        "            l = []\n",
        "            for part in first_name_parts:\n",
        "                if len(part) > 1:\n",
        "                    l.append(part)\n",
        "            return ' '.join(l)\n",
        "     \n",
        "    \n",
        "        \n",
        "with codecs.open(TARGET_FILE, 'w', encoding=ENCODING) as output_file:\n",
        "    writer = csv.DictWriter(output_file, fieldnames=[\n",
        "        'APPLICATION_ID',\n",
        "        'PI_ID', \n",
        "        'PI_NAME', \n",
        "        'PI_FIRST_NAME',\n",
        "        'NB_PI_IDS',\n",
        "        'NB_PI_NAMES',\n",
        "        'CONTACT_PI_ID_STATUS', \n",
        "        'CONTACT_PI_NAME_STATUS',\n",
        "        'RAW_PI_IDS',\n",
        "        'RAW_PI_NAMES'\n",
        "    ], dialect=csv.excel_tab)\n",
        "    writer.writeheader()\n",
        "\n",
        "    with codecs.open(SOURCE_FILE, 'r', encoding=ENCODING) as input_file:\n",
        "        reader = csv.DictReader(input_file, dialect=csv.excel_tab)\n",
        "\n",
        "        for index, input_row in enumerate(reader):\n",
        "\n",
        "            pi_ids_list = string_to_list(input_row['PI_IDS'])\n",
        "            pi_names_list = string_to_list(input_row['PI_NAMES'])\n",
        "\n",
        "            try:\n",
        "                contact_pi_id, pi_id_status = extract_contact_pi(pi_ids_list)\n",
        "                contact_pi_name, pi_name_status = extract_contact_pi(pi_names_list)\n",
        "            except Exception as e:\n",
        "                print('APPLICATION_ID', input_row['APPLICATION_ID'])\n",
        "                print('PI_IDS', input_row['PI_IDS'])\n",
        "                print('PI_NAMES', input_row['PI_NAMES'])\n",
        "                print('+++')\n",
        "                print(pi_ids_list)\n",
        "                print(pi_names_list)\n",
        "                print(e)\n",
        "                print('----------------')\n",
        "\n",
        "            dict_row = {\n",
        "                'APPLICATION_ID': input_row['APPLICATION_ID'],\n",
        "                'PI_ID': contact_pi_id, \n",
        "                'PI_NAME': contact_pi_name, \n",
        "                'PI_FIRST_NAME': extract_pi_first_name(contact_pi_name),\n",
        "                'NB_PI_IDS': len(pi_ids_list),\n",
        "                'NB_PI_NAMES': len(pi_names_list),\n",
        "                'CONTACT_PI_ID_STATUS': pi_id_status, \n",
        "                'CONTACT_PI_NAME_STATUS': pi_name_status,\n",
        "                'RAW_PI_IDS': input_row['PI_IDS'],\n",
        "                'RAW_PI_NAMES': input_row['PI_NAMES']\n",
        "            }\n",
        "            writer.writerow(dict_row)"
      ],
      "metadata": {
        "id": "uJ2PoiZ0Dckb"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: assign gender to first names"
      ],
      "metadata": {
        "id": "4-8ELwF6FB9X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# to do"
      ],
      "metadata": {
        "id": "9BcGbrPEFKX_"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data analysis"
      ],
      "metadata": {
        "id": "H01dnpBKFSI-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8RrQNIjWFUfG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}