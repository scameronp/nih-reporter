{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xtqSHg8_3i05"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "alc-1Vul3oaz"
   },
   "outputs": [],
   "source": [
    "# from urllib.request import urlretrieve\n",
    "import zipfile\n",
    "# import tempfile\n",
    "import csv\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import re\n",
    "from datetime import datetime\n",
    "from utils.csv_headers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wwMeFO8IA9EC"
   },
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dkRq4gKiWxtx"
   },
   "source": [
    "## Download CSV project files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fqDdxJHNW4Fl"
   },
   "outputs": [],
   "source": [
    "LOCAL_SOURCE_DIR = 'content/downloads'\n",
    "# # used to download zip files\n",
    "# TMP_DIR = tempfile.gettempdir()\n",
    "# BASE_URL = 'https://exporter.nih.gov/CSVs/final'\n",
    "\n",
    "\n",
    "# for file_name in [f'RePORTER_PRJ_C_FY{year}.zip' for year in range(1985, 2021)]:\n",
    "#     url = f'{BASE_URL}/{file_name}'\n",
    "\n",
    "#     # download file in local\n",
    "#     zip_path = f'{TMP_DIR}/{file_name}'\n",
    "#     urlretrieve(url, zip_path)\n",
    "\n",
    "    # unzip\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(LOCAL_SOURCE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6XFGnghtDLM4"
   },
   "source": [
    "## CSV files merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7aPtvpzIC0oh",
    "outputId": "3ee8057d-dfaf-4495-a02f-808bdb75b161"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'content/output.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     is_application_id_not_integer \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m is_integer(dict_row[APPLICATION_ID])   \n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m empty_column \u001b[38;5;129;01mor\u001b[39;00m is_application_id_not_integer\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mTARGET_FILE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m output_file:\n\u001b[1;32m     20\u001b[0m     writer \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mDictWriter(output_file, fieldnames\u001b[38;5;241m=\u001b[39mORDERED_HEADERS, dialect\u001b[38;5;241m=\u001b[39mcsv\u001b[38;5;241m.\u001b[39mexcel)\n\u001b[1;32m     21\u001b[0m     writer\u001b[38;5;241m.\u001b[39mwriteheader()\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'content/output.csv'"
     ]
    }
   ],
   "source": [
    "SOURCE_DIR = 'content/downloads'\n",
    "TARGET_FILE = 'content/output.csv'\n",
    "\n",
    "\n",
    "def is_integer(string):\n",
    "    try:\n",
    "        int(string)\n",
    "        return True\n",
    "    except ValueError as a:\n",
    "        return False\n",
    "\n",
    "\n",
    "def is_corrupted(dict_row):\n",
    "    empty_column = None in dict_row\n",
    "    is_application_id_not_integer = not is_integer(dict_row[APPLICATION_ID])   \n",
    "    return empty_column or is_application_id_not_integer\n",
    "\n",
    "\n",
    "with open(TARGET_FILE, 'w', encoding='utf-8') as output_file:\n",
    "    writer = csv.DictWriter(output_file, fieldnames=ORDERED_HEADERS, dialect=csv.excel)\n",
    "    writer.writeheader()\n",
    "\n",
    "    csv_files = sorted(os.listdir(SOURCE_DIR))\n",
    "\n",
    "    for csv_file_name in csv_files:\n",
    "        print(csv_file_name)\n",
    "\n",
    "        with open(SOURCE_DIR + '/' + csv_file_name, 'r', encoding='ISO-8859-1') as csv_file_descriptor:\n",
    "            reader = csv.DictReader(csv_file_descriptor, delimiter=',', quotechar='\"')\n",
    "            for index, dict_row in enumerate(reader):\n",
    "                if is_corrupted(dict_row):\n",
    "                    print(csv_file_name, index, dict_row[APPLICATION_ID])\n",
    "                else:\n",
    "                    upper_dict = dict()\n",
    "                    for key, value in dict_row.items():\n",
    "                        try:\n",
    "                            # letter case uniformization\n",
    "                            upper_dict[key.upper()] = value.replace(\"\\n\", \"\")\n",
    "                        except Exception as e:\n",
    "                            print(e)\n",
    "                            print(dict_row)\n",
    "                            print(csv_file_name)\n",
    "                            #raise e\n",
    "                    writer.writerow(upper_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-SeT387SDQ9L"
   },
   "source": [
    "## Contact PIs first name extraction & gender assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mm4-ol6lWmtG"
   },
   "outputs": [],
   "source": [
    "SOURCE_FILE = 'content/output.csv'\n",
    "TARGET_FILE = 'content/enhanced-output.csv'\n",
    "ENCODING = 'utf-8'\n",
    "\n",
    "\n",
    "def string_to_list(string):\n",
    "    pi_list = []\n",
    "    for string_part in string.rstrip('; ').split(';'):\n",
    "        string_part = string_part.strip(', ').replace('\"', '')\n",
    "        if string_part != '':\n",
    "            pi_list.append(string_part)\n",
    "    return pi_list\n",
    "\n",
    "\n",
    "def filter_contact_pi(pi_ids_or_names_list):\n",
    "    filtered_list = []\n",
    "    for item in pi_ids_or_names_list: \n",
    "         if '(contact)' in item:\n",
    "            filtered_list.append(item)\n",
    "    return filtered_list\n",
    "\n",
    "\n",
    "def extract_contact_pi(pi_ids_or_names_list):\n",
    "    if len(pi_ids_or_names_list) == 0:\n",
    "        return None, \"no_value\"\n",
    "    elif len(pi_ids_or_names_list) == 1:\n",
    "        return pi_ids_or_names_list[0], \"single_value\"\n",
    "    else:              \n",
    "        filtered_pi_ids_or_names = filter_contact_pi(pi_ids_or_names_list)\n",
    "        if len(filtered_pi_ids_or_names) == 0:\n",
    "            return pi_ids_or_names_list[0], \"multiple_values_but_no_explicit_contact_first_chosen\"\n",
    "        elif len(filtered_pi_ids_or_names) == 1:\n",
    "            return filtered_pi_ids_or_names[0], \"multiple_values_and_single_explicit_contact\"\n",
    "        else:\n",
    "            return filtered_pi_ids_or_names[0], \"multiple_values_and_multiple_explicit_contacts_first_chosen\"\n",
    "\n",
    "\n",
    "def normalize_first_name(first_name):\n",
    "    first_name = re.sub('[\\.\\-\\;\\,]', '', first_name)\n",
    "    first_name = re.sub(' +', ' ', first_name)\n",
    "    first_name_parts = first_name.strip(' ').split(' ')\n",
    "    l = []\n",
    "    for part in first_name_parts:\n",
    "        if len(part) > 1:\n",
    "            l.append(part)\n",
    "    return ' '.join(l).upper()\n",
    "\n",
    "\n",
    "def extract_pi_first_name(full_name):\n",
    "    if full_name is None:\n",
    "        return None\n",
    "    else:\n",
    "        full_name_list = full_name.split(',')\n",
    "        if len(full_name_list) <= 1:\n",
    "            return None\n",
    "        else:\n",
    "            return normalize_first_name(full_name_list[1].replace('(contact)', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TxWmUc8oXPrL"
   },
   "outputs": [],
   "source": [
    "# upload and clean gender_US_names.csv list\n",
    "\n",
    "with open('content/gender_US_names.csv', 'r', encoding='UTF-8-sig') as csv_file_descriptor:\n",
    "    gender_dataset = csv.DictReader(csv_file_descriptor, delimiter=',', quotechar='\"')\n",
    "\n",
    "    gender_dict = {}\n",
    "\n",
    "    for item in gender_dataset:\n",
    "        normalized_first_name = normalize_first_name(item['Name'])\n",
    "        gender_dict[normalized_first_name] = item['Gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uJ2PoiZ0Dckb"
   },
   "outputs": [],
   "source": [
    "# enhance output.csv file with contact PIs extraction and gender assignment\n",
    "       \n",
    "with open(TARGET_FILE, 'w', encoding=ENCODING) as output_file:\n",
    "    writer = csv.DictWriter(output_file, fieldnames=[\n",
    "        APPLICATION_ID,\n",
    "        ACTIVITY,\n",
    "        ADMINISTERING_IC,\n",
    "        APPLICATION_TYPE,\n",
    "        ARRA_FUNDED,\n",
    "        AWARD_NOTICE_DATE,\n",
    "        BUDGET_START,\n",
    "        BUDGET_END,\n",
    "        CFDA_CODE,\n",
    "        CORE_PROJECT_NUM,\n",
    "        ED_INST_TYPE,\n",
    "        FOA_NUMBER,\n",
    "        FULL_PROJECT_NUM,\n",
    "        FUNDING_ICS,\n",
    "        FUNDING_MECHANISM,\n",
    "        FY,\n",
    "        IC_NAME,\n",
    "        NIH_SPENDING_CATS,\n",
    "        ORG_CITY,\n",
    "        ORG_COUNTRY,\n",
    "        ORG_DEPT,\n",
    "        ORG_DISTRICT,\n",
    "        ORG_DUNS,\n",
    "        ORG_FIPS,\n",
    "        ORG_IPF_CODE,\n",
    "        ORG_NAME,\n",
    "        ORG_STATE,\n",
    "        ORG_ZIPCODE,\n",
    "        PHR,\n",
    "        PI_IDS,\n",
    "        PI_NAMES,\n",
    "\n",
    "        NB_PI_IDS,\n",
    "        NB_PI_NAMES,\n",
    "        CONTACT_PI_ID, \n",
    "        CONTACT_PI_NAME, \n",
    "        CONTACT_PI_ID_STATUS, \n",
    "        CONTACT_PI_NAME_STATUS,\n",
    "        CONTACT_PI_FIRST_NAME,\n",
    "        CONTACT_PI_GENDER,\n",
    "\n",
    "        PROGRAM_OFFICER_NAME,\n",
    "        PROJECT_START,\n",
    "        PROJECT_END,\n",
    "        PROJECT_TERMS,\n",
    "        PROJECT_TITLE,\n",
    "        SERIAL_NUMBER,\n",
    "        STUDY_SECTION,\n",
    "        STUDY_SECTION_NAME,\n",
    "        SUBPROJECT_ID,\n",
    "        SUFFIX,\n",
    "        SUPPORT_YEAR,\n",
    "        DIRECT_COST_AMT,\n",
    "        INDIRECT_COST_AMT,\n",
    "        TOTAL_COST,\n",
    "        TOTAL_COST_SUB_PROJECT\n",
    "    ], dialect=csv.excel)\n",
    "    writer.writeheader()\n",
    "\n",
    "\n",
    "    with open(SOURCE_FILE, 'r', encoding=ENCODING) as input_file:\n",
    "        reader = csv.DictReader(input_file, dialect=csv.excel)\n",
    "\n",
    "        for index, input_row in enumerate(reader):\n",
    "\n",
    "            pi_ids_list = string_to_list(input_row[PI_IDS])\n",
    "            pi_names_list = string_to_list(input_row[PI_NAMES])\n",
    "\n",
    "            try:\n",
    "                contact_pi_id, pi_id_status = extract_contact_pi(pi_ids_list)\n",
    "                contact_pi_name, pi_name_status = extract_contact_pi(pi_names_list)\n",
    "            except Exception as e:\n",
    "                print('APPLICATION_ID', input_row[APPLICATION_ID])\n",
    "                print('PI_IDS', input_row[PI_IDS])\n",
    "                print('PI_NAMES', input_row[PI_NAMES])\n",
    "                print('+++')\n",
    "                print(pi_ids_list)\n",
    "                print(pi_names_list)\n",
    "                print(e)\n",
    "                print('----------------')\n",
    "\n",
    "            contact_pi_first_name = extract_pi_first_name(contact_pi_name)\n",
    "\n",
    "            dict_row = {\n",
    "                APPLICATION_ID: input_row[APPLICATION_ID],\n",
    "                ACTIVITY: input_row[ACTIVITY],\n",
    "                ADMINISTERING_IC: input_row[ADMINISTERING_IC],\n",
    "                APPLICATION_TYPE: input_row[APPLICATION_TYPE],\n",
    "                ARRA_FUNDED: input_row[ARRA_FUNDED],\n",
    "                AWARD_NOTICE_DATE: input_row[AWARD_NOTICE_DATE],\n",
    "                BUDGET_START: input_row[BUDGET_START],\n",
    "                BUDGET_END: input_row[BUDGET_END],\n",
    "                CFDA_CODE: input_row[CFDA_CODE],\n",
    "                CORE_PROJECT_NUM: input_row[CORE_PROJECT_NUM],\n",
    "                ED_INST_TYPE: input_row[ED_INST_TYPE],\n",
    "                FOA_NUMBER: input_row[FOA_NUMBER],\n",
    "                FULL_PROJECT_NUM: input_row[FULL_PROJECT_NUM],\n",
    "                FUNDING_ICS: input_row[FUNDING_ICS],\n",
    "                FUNDING_MECHANISM: input_row[FUNDING_MECHANISM],\n",
    "                FY: input_row[FY],\n",
    "                IC_NAME: input_row[IC_NAME],\n",
    "                NIH_SPENDING_CATS: input_row[NIH_SPENDING_CATS],\n",
    "                ORG_CITY: input_row[ORG_CITY],\n",
    "                ORG_COUNTRY: input_row[ORG_COUNTRY],\n",
    "                ORG_DEPT: input_row[ORG_DEPT],\n",
    "                ORG_DISTRICT: input_row[ORG_DISTRICT],\n",
    "                ORG_DUNS: input_row[ORG_DUNS],\n",
    "                ORG_FIPS: input_row[ORG_FIPS],\n",
    "                ORG_IPF_CODE: input_row[ORG_IPF_CODE],\n",
    "                ORG_NAME: input_row[ORG_NAME],\n",
    "                ORG_STATE: input_row[ORG_STATE],\n",
    "                ORG_ZIPCODE: input_row[ORG_ZIPCODE],\n",
    "                PHR: input_row[PHR],\n",
    "                PI_IDS: input_row[PI_IDS],\n",
    "                PI_NAMES: input_row[PI_NAMES],\n",
    "\n",
    "                NB_PI_IDS: len(pi_ids_list),\n",
    "                NB_PI_NAMES: len(pi_names_list),\n",
    "                CONTACT_PI_ID: contact_pi_id, \n",
    "                CONTACT_PI_NAME: contact_pi_name, \n",
    "                CONTACT_PI_ID_STATUS: pi_id_status, \n",
    "                CONTACT_PI_NAME_STATUS: pi_name_status,\n",
    "                CONTACT_PI_FIRST_NAME: contact_pi_first_name,\n",
    "                CONTACT_PI_GENDER: gender_dict.get(contact_pi_first_name),\n",
    "\n",
    "                PROGRAM_OFFICER_NAME: input_row[PROGRAM_OFFICER_NAME],\n",
    "                PROJECT_START: input_row[PROJECT_START],\n",
    "                PROJECT_END: input_row[PROJECT_END],\n",
    "                PROJECT_TERMS: input_row[PROJECT_TERMS],\n",
    "                PROJECT_TITLE: input_row[PROJECT_TITLE],\n",
    "                SERIAL_NUMBER: input_row[SERIAL_NUMBER],\n",
    "                STUDY_SECTION: input_row[STUDY_SECTION],\n",
    "                STUDY_SECTION_NAME: input_row[STUDY_SECTION_NAME],\n",
    "                SUBPROJECT_ID: input_row[SUBPROJECT_ID],\n",
    "                SUFFIX: input_row[SUFFIX],\n",
    "                SUPPORT_YEAR: input_row[SUPPORT_YEAR],\n",
    "                DIRECT_COST_AMT: input_row[DIRECT_COST_AMT],\n",
    "                INDIRECT_COST_AMT: input_row[INDIRECT_COST_AMT],\n",
    "                TOTAL_COST: input_row[TOTAL_COST],\n",
    "                TOTAL_COST_SUB_PROJECT: input_row[TOTAL_COST_SUB_PROJECT]\n",
    "            }\n",
    "            writer.writerow(dict_row)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NIH-RePORTER-preprocessing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
